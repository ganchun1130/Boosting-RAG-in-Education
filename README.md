# Boosting-RAG-in-Education
## 这是一份集成了RAG和微调以及思维链的LLM应用程序

在这个文档中，我们详细介绍了如何从零开始构建一个集成了RAG（Retrieval Augmented Generation）、模型微调以及思维链的大型语言模型（LLM）应用程序。我们希望通过这份实践经历，能够帮助到您。

## 使用说明

1. **构建知识库**
   运行`ingest.py`文件，用来构建知识库。在`config`文件中可以指定知识文件路径以及选用的embedding模型。

2. **选择系列模型**
   打开`API`文件夹，选择一个系列模型，可以是qwen，也可以是chatglm，这些模型的api调用代码均可以在各自的官方仓库中找到，实在不行用ollama也可以。

3. **服务启动后测试**
   服务启动后，您可以适当进行测试。如果要使用query-expansion，应该启动两个模型，最好是一个7b，一个14b。

4. **使用Web页面**
   如果你想使用web页面，你可以直接运行`Chat`文件夹下的`app.py`，但也要配置一些参数。

5. **评估数据**
   如果你想直接评估数据，你可以运行`RAG`目录下的`build_ragas_date_full.py`文件。

## 注意事项

- 我是使用A100显卡进行开发的！
- 库文件在`requirements.txt`文件中！

就先说到这里，以后想到什么再补充吧。
