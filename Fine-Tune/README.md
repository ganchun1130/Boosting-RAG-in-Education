# ğŸŒˆğŸ‘‹ å¾®è°ƒä»£ç èµ„æºä¸è‡´è°¢

## âœ¨ å¾®è°ƒä»£ç è®¿é—®

æœ¬é¡¹ç›®ä¸­æ‰€ä½¿ç”¨çš„å¾®è°ƒä»£ç å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è·å–ï¼š

- [GitHubä»“åº“](https://github.com/hiyouga/LLaMA-Factory)

## âœ¨ è‡´è°¢

ç‰¹åˆ«é¸£è°¢ **LlamaFactory** é¡¹ç›®çš„å¼€æºè´¡çŒ®ï¼Œè¯¥å·¥ä½œæå¤§åœ°ç®€åŒ–äº†å¯¹100å¤šç§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒæµç¨‹ï¼Œä¸ºç ”ç©¶å’Œåº”ç”¨`llama`ç³»åˆ—æ¨¡å‹æä¾›äº†å¼ºå¤§çš„æ”¯æŒä¸ä¾¿åˆ©ï¼

## âœ¨ å‚è€ƒæ–‡çŒ®

```bibtex

@article{zheng2024llamafactory,
  title         = {LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author        = {Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Yongqiang Ma},
  journal       = {arXiv preprint arXiv:2403.13372},
  year          = {2024},
  url           = {http://arxiv.org/abs/2403.13372}
}
